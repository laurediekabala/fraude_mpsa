from flask import Blueprint, request, jsonify
from services.drift_detection import DriftDetector
import pandas as pd
import io
import os

drift_bp = Blueprint("drift", __name__)
detector = DriftDetector()

@drift_bp.route("/check", methods=["POST"])
def check_drift():
    """
    V√©rifie le drift pour une nouvelle pr√©diction
    POST /drift/check avec JSON data
    """
    try:
        data = request.json
        
        if not data:
            return jsonify({"error": "Donn√©es JSON vides"}), 400
        
        drift_report = detector.check_drift(data)
        
        return jsonify(drift_report)
    
    except Exception as e:
        print(f"‚ùå Erreur dans /drift/check : {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@drift_bp.route("/summary", methods=["GET"])
def drift_summary():
    """
    Retourne un r√©sum√© de l'√©tat du drift
    GET /drift/summary
    """
    try:
        summary = detector.get_drift_summary()
        return jsonify(summary)
    
    except Exception as e:
        print(f"‚ùå Erreur dans /drift/summary : {e}")
        return jsonify({"error": str(e)}), 500


@drift_bp.route("/baseline/create", methods=["POST"])
def create_baseline():
    """
    Cr√©e une nouvelle baseline √† partir d'une liste de donn√©es
    POST /drift/baseline/create avec JSON list
    """
    try:
        data_list = request.json
        
        if not isinstance(data_list, list):
            return jsonify({"error": "Les donn√©es doivent √™tre une liste"}), 400
        
        baseline = detector.create_baseline(data_list)
        detector.save_baseline(baseline)
        
        # Extraire les features (exclure les m√©tadonn√©es)
        features = [f for f in baseline.get('features', []) if f not in ['timestamp', 'n_samples']]
        
        return jsonify({
            "status": "SUCCESS",
            "message": f"Baseline cr√©√©e avec {len(data_list)} √©chantillons",
            "baseline": baseline,
            "baseline_summary": {
                "total_samples": baseline.get('n_samples', len(data_list)),
                "features": features,
                "created_at": baseline.get('created_at', 'N/A')
            }
        })
    
    except Exception as e:
        print(f"‚ùå Erreur dans /drift/baseline/create : {e}")
        return jsonify({"error": str(e)}), 500


@drift_bp.route("/upload/training-data", methods=["POST"])
def upload_training_data():
    """
    Upload un fichier CSV volumineux et cr√©e une baseline
    POST /drift/upload/training-data (multipart/form-data)
    
    Param√®tres:
        - file: Fichier CSV
        - max_rows: Nombre max de lignes √† traiter (d√©faut: 50000)
        - sample_ratio: Ratio d'√©chantillonnage (d√©faut: 1.0 = 100%)
    """
    try:
        # V√©rifier que le fichier est pr√©sent
        if "file" not in request.files:
            return jsonify({"error": "Aucun fichier fourni"}), 400
        
        file = request.files["file"]
        if file.filename == "":
            return jsonify({"error": "Fichier vide"}), 400
        
        if not file.filename.endswith(".csv"):
            return jsonify({"error": "Seuls les fichiers CSV sont accept√©s"}), 400
        
        # R√©cup√©rer les param√®tres
        max_rows = request.form.get("max_rows", 50000, type=int)
        sample_ratio = request.form.get("sample_ratio", 1.0, type=float)
        
        print(f"üì§ Upload re√ßu: {file.filename} ({max_rows} lignes max, {sample_ratio*100}% sampling)")
        
        # Lire le fichier par chunks pour √©conomiser la m√©moire
        chunks = []
        chunk_size = 10000
        rows_read = 0
        
        for chunk in pd.read_csv(file, chunksize=chunk_size, nrows=max_rows):
            chunks.append(chunk)
            rows_read += len(chunk)
            print(f"  ‚úì Chunk lu: {rows_read} lignes")
        
        if not chunks:
            return jsonify({"error": "Fichier CSV vide"}), 400
        
        df = pd.concat(chunks, ignore_index=True)
        
        # Appliquer le ratio d'√©chantillonnage si demand√©
        if sample_ratio < 1.0:
            df = df.sample(frac=sample_ratio, random_state=42)
            print(f"  ‚úì √âchantillonnage appliqu√©: {len(df)} lignes retenues")
        
        # Convertir en liste de dictionnaires
        data_list = df.to_dict("records")
        
        # Cr√©er et sauvegarder la baseline
        baseline = detector.create_baseline(data_list)
        detector.save_baseline(baseline)
        
        return jsonify({
            "status": "SUCCESS",
            "message": f"Baseline cr√©√©e avec {len(data_list)} √©chantillons",
            "baseline_summary": {
                "total_samples": len(data_list),
                "features": baseline.get("features", []),
                "created_at": baseline.get("created_at")
            }
        }), 200
    
    except Exception as e:
        print(f"‚ùå Erreur dans /drift/upload/training-data : {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500
