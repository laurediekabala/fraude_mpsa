import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import requests
from pathlib import Path

def api_call(endpoint, method="GET", data=None):
    """Helper pour appeler l'API"""
    try:
        url = f"http://localhost:5000{endpoint}"
        if method == "GET":
            response = requests.get(url)
        else:
            response = requests.post(url, json=data)
        return response.json()
    except Exception as e:
        return {"error": str(e)}

def load_csv_streaming(csv_path, max_rows=None, sample_ratio=1.0, chunksize=10000):
    """
    Charger un fichier CSV volumineux par chunks (streaming)
    """
    chunks = []
    rows_read = 0
    
    progress_bar = st.progress(0)
    status = st.empty()
    
    try:
        for i, chunk in enumerate(pd.read_csv(csv_path, chunksize=chunksize, nrows=max_rows)):
            chunks.append(chunk)
            rows_read += len(chunk)
            
            # Mise Ã  jour de la barre de progression
            progress = min(int((rows_read / max_rows) * 100) if max_rows else (i+1)*10, 95)
            progress_bar.progress(progress)
            status.text(f"ğŸ“– {rows_read:,} lignes chargÃ©es...")
            
            if max_rows and rows_read >= max_rows:
                break
        
        progress_bar.progress(100)
        status.text(f"âœ… {rows_read:,} lignes chargÃ©es avec succÃ¨s!")
        
        if chunks:
            df = pd.concat(chunks, ignore_index=True)
            
            # Appliquer le sampling si nÃ©cessaire
            if sample_ratio < 1.0:
                df = df.sample(frac=sample_ratio, random_state=42)
                status.text(f"âœ… {len(df):,} lignes aprÃ¨s Ã©chantillonnage")
            
            return df
        else:
            st.error("âŒ Aucune donnÃ©e chargÃ©e")
            return None
    
    except Exception as e:
        st.error(f"âŒ Erreur lors du chargement: {e}")
        return None

def show_page():
    st.markdown("## ğŸ“Š Drift Detection & Model Monitoring")
    st.markdown("---")
    
    st.info("""
    ğŸ” **Data Drift Detection** surveille si les donnÃ©es changent au fil du temps.
    Si le drift est dÃ©tectÃ©, le modÃ¨le doit Ãªtre rÃ©entraÃ®nÃ©!
    """)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SECTION: Charger les donnÃ©es d'entraÃ®nement
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    st.subheader("ğŸ“¥ Charger les DonnÃ©es d'EntraÃ®nement")
    
    # CrÃ©er des onglets pour les deux options d'upload
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ Streamlit Upload (<200MB)", "ğŸš€ API Upload (fichiers volumineux)", "ğŸ’¾ Chemin Local (Streaming)"])
    
    with tab1:
        st.markdown("""
        âœ… **Avantages**: Simple et intuitif dans Streamlit
        âš ï¸ **Limitation**: Maximum 200 MB
        """)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Option pour limiter le nombre de lignes
            max_rows = st.slider(
                "Nombre max de lignes Ã  charger",
                min_value=100,
                max_value=50000,
                value=5000,
                step=500,
                help="Charge seulement N premiÃ¨res lignes pour Ã©conomiser la mÃ©moire",
                key="max_rows_1"
            )
        
        with col2:
            # Option pour Ã©chantillonner
            sample_ratio = st.slider(
                "Ratio d'Ã©chantillonnage",
                min_value=0.1,
                max_value=1.0,
                value=0.5,
                step=0.1,
                help="Utiliser qu'un pourcentage des donnÃ©es (ex: 0.5 = 50%)",
                key="sample_ratio_1"
            )
        
        with col3:
            st.write("")  # Spacing
        
        uploaded_file = st.file_uploader(
            "ğŸ“¤ Uploadez un fichier CSV (< 200 MB)",
            type=['csv'],
            help="Format: CSV avec les colonnes de features",
            key="file_uploader_1"
        )
        
        if uploaded_file is not None:
            st.success("âœ… Fichier dÃ©tectÃ©!")
            
            try:
                # Afficher la progression
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Lire seulement les premiÃ¨res lignes
                status_text.text(f"ğŸ“– Chargement des {max_rows} premiÃ¨res lignes...")
                
                # Lire par chunks pour Ã©conomiser la mÃ©moire
                chunks = []
                chunk_size = 10000
                
                for i, chunk in enumerate(pd.read_csv(uploaded_file, chunksize=chunk_size, nrows=max_rows)):
                    chunks.append(chunk)
                    progress = int((i + 1) / (max_rows / chunk_size) * 30)
                    progress_bar.progress(min(progress, 30))
                
                df = pd.concat(chunks, ignore_index=True) if chunks else pd.DataFrame()
                progress_bar.progress(40)
                
                if len(df) == 0:
                    st.error("âŒ Aucune donnÃ©e chargÃ©e!")
                else:
                    status_text.text(f"ğŸ“Š {len(df)} lignes chargÃ©es, {len(df.columns)} colonnes")
                    
                    # Afficher un aperÃ§u
                    with st.expander("ğŸ‘ï¸ AperÃ§u des donnÃ©es"):
                        st.dataframe(df.head(10), use_container_width=True)
                        st.write(f"**Colonnes**: {list(df.columns)}")
                    
                    progress_bar.progress(60)
                    
                    # Ã‰chantillonner si nÃ©cessaire
                    if sample_ratio < 1.0:
                        status_text.text(f"ğŸ² Ã‰chantillonnage Ã  {sample_ratio*100:.0f}%...")
                        df = df.sample(frac=sample_ratio, random_state=42)
                        status_text.text(f"âœ… {len(df)} lignes aprÃ¨s Ã©chantillonnage")
                    
                    progress_bar.progress(80)
                    
                    # Bouton pour crÃ©er la baseline
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if st.button("ğŸ”„ CrÃ©er baseline Ã  partir de ce fichier", key="create_baseline_1"):
                            # Convertir DataFrame en liste de dictionnaires
                            data_list = df.to_dict('records')
                            
                            status_text.text("â³ Envoi des donnÃ©es Ã  l'API...")
                            progress_bar.progress(90)
                            
                            # Appeler l'API pour crÃ©er la baseline
                            result = api_call("/drift/baseline/create", method="POST", data=data_list)
                            
                            progress_bar.progress(100)
                            
                            if "error" in result:
                                st.error(f"âŒ Erreur: {result['error']}")
                                status_text.text("âŒ Erreur lors de la crÃ©ation de la baseline")
                            else:
                                st.success(f"âœ… Baseline crÃ©Ã©e avec {len(data_list)} Ã©chantillons!")
                                status_text.text("âœ… Baseline crÃ©Ã©e avec succÃ¨s!")
                                st.balloons()
                                
                                # Afficher les stats
                                with st.expander("ğŸ“Š DÃ©tails de la baseline"):
                                    st.json(result.get('baseline', {}))
                    
                    with col2:
                        st.info(f"ğŸ’¡ DonnÃ©es chargÃ©es: ~{len(df) * 0.001:.1f} MB")
                        
            except Exception as e:
                st.error(f"âŒ Erreur lors de la lecture du fichier: {e}")
                status_text.text("âŒ Erreur!")
    
    with tab2:
        st.markdown("""
        âœ… **Avantages**: Accepte fichiers > 200 MB, plus rapide, pas de limite pratique
        â„¹ï¸ **Utilisation**: Python script ou PowerShell command
        """)
        
        st.info("""
        **Pour uploader des fichiers volumineux (> 200 MB):**
        
        1. **Via Python**: 
           ```bash
           python upload_training_data.py "C:\\chemin\\vers\\MPSA.csv" --max-rows 50000 --sample-ratio 1.0
           ```
        
        2. **Via PowerShell**:
           ```powershell
           .\\upload_data.ps1 -CsvFile "C:\\chemin\\vers\\MPSA.csv" -MaxRows 50000 -SampleRatio 1.0
           ```
        
        **ParamÃ¨tres optionnels:**
        - `--max-rows`: Nombre max de lignes Ã  traiter (dÃ©faut: 50000)
        - `--sample-ratio`: Ratio d'Ã©chantillonnage 0.0-1.0 (dÃ©faut: 1.0)
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            max_rows_2 = st.number_input(
                "Nombre max de lignes Ã  traiter",
                min_value=100,
                max_value=1000000,
                value=50000,
                step=1000,
                help="Plus cette valeur est Ã©levÃ©e, plus l'upload prendra de temps",
                key="max_rows_2"
            )
        
        with col2:
            sample_ratio_2 = st.slider(
                "Ratio d'Ã©chantillonnage (optionnel)",
                min_value=0.1,
                max_value=1.0,
                value=1.0,
                step=0.1,
                help="Utiliser qu'un pourcentage des donnÃ©es",
                key="sample_ratio_2"
            )
        
        st.markdown("---")
        
        st.subheader("ğŸ“Œ Commandes Rapides")
        
        # Exemple de commande Python
        st.code(
            f'python upload_training_data.py "C:\\\\data\\\\MPSA.csv" --max-rows {int(max_rows_2)} --sample-ratio {sample_ratio_2}',
            language="bash"
        )
        
        # Exemple de commande PowerShell
        st.code(
            f'.\\upload_data.ps1 -CsvFile "C:\\data\\MPSA.csv" -MaxRows {int(max_rows_2)} -SampleRatio {sample_ratio_2}',
            language="powershell"
        )
        
        st.markdown("---")
        
        st.subheader("ğŸ“¥ Suivi de l'Upload")
        
        if st.button("ğŸ”„ VÃ©rifier l'Ã©tat de la baseline", key="check_baseline_api"):
            summary = api_call("/drift/summary")
            
            if "error" not in summary and summary.get("status") != "NO_BASELINE":
                st.success(f"âœ… Baseline disponible depuis: {summary.get('baseline_created', 'N/A')}")
                st.metric("Ã‰chantillons", summary.get('baseline_samples', 'N/A'))
            else:
                st.warning("âš ï¸ Aucune baseline trouvÃ©e. Lancez d'abord un upload!")
    
    with tab3:
        st.markdown("""
        âœ… **Avantages**: Ultra rapide, pas d'upload rÃ©seau, streaming en mÃ©moire
        ğŸ’¾ **Utilisation**: Pour fichiers locaux (mÃªme rÃ©seau local)
        """)
        
        st.success("""
        âš¡ **MÃ‰THODE LA PLUS RAPIDE!**
        
        Charger directement depuis un chemin local avec streaming en mÃ©moire.
        Ideal pour les fichiers > 500 MB!
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            csv_path = st.text_input(
                "ğŸ“ Chemin local du fichier CSV",
                value="E:/pipeline/MPSA.csv",
                help="Exemple: E:/pipeline/MPSA.csv ou C:/data/file.csv",
                key="local_csv_path"
            )
        
        with col2:
            st.write("")  # Spacing
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            max_rows_3 = st.number_input(
                "Nombre max de lignes",
                min_value=100,
                max_value=1000000,
                value=50000,
                step=1000,
                help="Limite du nombre de lignes Ã  charger",
                key="max_rows_3"
            )
        
        with col2:
            sample_ratio_3 = st.slider(
                "Ratio d'Ã©chantillonnage",
                min_value=0.1,
                max_value=1.0,
                value=1.0,
                step=0.1,
                help="Pourcentage de donnÃ©es Ã  utiliser",
                key="sample_ratio_3"
            )
        
        with col3:
            chunksize_3 = st.number_input(
                "Taille des chunks",
                min_value=1000,
                max_value=50000,
                value=10000,
                step=1000,
                help="Lignes par chunk (plus bas = moins de RAM)",
                key="chunksize_3"
            )
        
        st.markdown("---")
        
        if st.button("ğŸ“‚ Charger et crÃ©er baseline", key="load_local_file"):
            # VÃ©rifier que le fichier existe
            file_path = Path(csv_path)
            
            if not file_path.exists():
                st.error(f"âŒ Fichier non trouvÃ©: {csv_path}")
                st.info(f"ğŸ’¡ VÃ©rifiez le chemin. Fichier existe? {file_path.exists()}")
            else:
                file_size_mb = file_path.stat().st_size / (1024 * 1024)
                st.info(f"ğŸ“Š Fichier: {file_path.name} ({file_size_mb:.2f} MB)")
                
                try:
                    # Charger les donnÃ©es par streaming
                    st.subheader("â³ Chargement en cours...")
                    df = load_csv_streaming(
                        str(file_path),
                        max_rows=max_rows_3,
                        sample_ratio=sample_ratio_3,
                        chunksize=int(chunksize_3)
                    )
                    
                    if df is not None and len(df) > 0:
                        st.success(f"âœ… {len(df):,} lignes chargÃ©es!")
                        
                        # Afficher aperÃ§u
                        with st.expander("ğŸ‘ï¸ AperÃ§u des donnÃ©es"):
                            st.dataframe(df.head(10), use_container_width=True)
                            st.write(f"**Colonnes**: {list(df.columns)}")
                            st.write(f"**Types**: {dict(df.dtypes)}")
                        
                        # CrÃ©er la baseline
                        st.subheader("ğŸ”„ CrÃ©ation de la baseline...")
                        
                        progress_bar = st.progress(0)
                        status = st.empty()
                        
                        # Convertir en liste de dictionnaires
                        status.text("ğŸ“ Conversion des donnÃ©es...")
                        progress_bar.progress(30)
                        data_list = df.to_dict('records')
                        
                        # Appeler l'API
                        status.text("ğŸ“¤ Envoi Ã  l'API...")
                        progress_bar.progress(70)
                        result = api_call("/drift/baseline/create", method="POST", data=data_list)
                        progress_bar.progress(100)
                        
                        if "error" in result:
                            st.error(f"âŒ Erreur API: {result['error']}")
                            status.text("âŒ Erreur!")
                        else:
                            st.success("âœ… Baseline crÃ©Ã©e avec succÃ¨s!")
                            status.text("âœ… Baseline crÃ©Ã©e!")
                            st.balloons()
                            
                            # Afficher les dÃ©tails (mÃªme format pour tous les endpoints)
                            summary = result.get('baseline_summary', {})
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.metric("Ã‰chantillons", summary.get('total_samples', 'N/A'))
                            with col2:
                                st.metric("Features", len(summary.get('features', [])))
                            with col3:
                                created_at = summary.get('created_at', 'N/A')
                                created_at = created_at[:10] if isinstance(created_at, str) and len(created_at) > 10 else created_at
                                st.metric("CrÃ©Ã©e le", created_at)
                            
                            with st.expander("ğŸ“Š DÃ©tails complets"):
                                st.json(result)
                    else:
                        st.error("âŒ Erreur lors du chargement des donnÃ©es")
                
                except Exception as e:
                    st.error(f"âŒ Erreur: {e}")
                    import traceback
                    st.code(traceback.format_exc())
    
    st.markdown("---")
    
    summary = api_call("/drift/summary")
    
    if "error" in summary:
        st.error(f"âŒ Erreur: {summary['error']}")
        st.warning("La baseline doit Ãªtre crÃ©Ã©e d'abord. Voir la section ci-dessous.")
    elif summary.get("status") == "NO_BASELINE":
        st.warning("âš ï¸ Aucune baseline disponible. CrÃ©ez-en une avec les donnÃ©es d'entraÃ®nement!")
        
        if st.button("ğŸ“¥ CrÃ©er une baseline de test"):
            # CrÃ©er une baseline de test
            test_data = [
                {
                    "step": 100 + i,
                    "type": "TRANSFER",
                    "amount": 1000 + i*100,
                    "oldbalanceOrg": 5000,
                    "newbalanceOrig": 4000,
                    "oldbalanceDest": 1000,
                    "newbalanceDest": 2000,
                    "hour": 10,
                    "erreur_orig": 0.1,
                    "erreur_dst": 0.1,
                    "videur_orig": 0,
                    "videur_dest": 0
                }
                for i in range(100)
            ]
            
            result = api_call("/drift/baseline/create", method="POST", data=test_data)
            
            if "error" in result:
                st.error(f"âŒ Erreur: {result['error']}")
            else:
                st.success("âœ… Baseline crÃ©Ã©e avec succÃ¨s!")
                st.json(result)
    else:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Status", "âœ… Baseline disponible")
        
        with col2:
            st.metric("CrÃ©Ã©e le", summary.get("baseline_created", "N/A")[:10])
        
        with col3:
            st.metric("Ã‰chantillons", summary.get("baseline_samples", "N/A"))
        
        # Afficher les features dans la baseline
        st.subheader("ğŸ“‹ Features dans la Baseline")
        features_list = summary.get("features", [])
        features_list = [f for f in features_list if f not in ['timestamp', 'n_samples']]
        
        col_count = 4
        cols = st.columns(col_count)
        for idx, feature in enumerate(features_list):
            with cols[idx % col_count]:
                st.write(f"âœ“ {feature}")
        
        st.markdown("---")
        
        # Section 2: VÃ©rifier le drift sur la derniÃ¨re prÃ©diction
        st.subheader("ğŸ” VÃ©rification du Drift")
        
        if 'last_probability' in st.session_state and 'last_data_sent' in st.session_state:
            st.info("VÃ©rification en cours sur la derniÃ¨re prÃ©diction...")
            
            # Appeler l'API de drift
            drift_report = api_call("/drift/check", method="POST", data=st.session_state.last_data_sent)
            
            if "error" in drift_report:
                st.error(f"âŒ Erreur: {drift_report['error']}")
            else:
                # Afficher le rÃ©sumÃ© du drift
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    status = "ğŸ”´ DRIFT DÃ‰TECTÃ‰" if drift_report.get('overall_drift') else "ğŸŸ¢ Pas de drift"
                    st.metric("Status Global", status)
                
                with col2:
                    st.metric(
                        "Features affectÃ©es",
                        f"{drift_report.get('drift_count', 0)}/{drift_report.get('total_features', 0)}"
                    )
                
                with col3:
                    st.metric(
                        "Pourcentage de drift",
                        f"{drift_report.get('drift_percentage', 0):.1f}%"
                    )
                
                st.markdown("---")
                
                # Tableau dÃ©taillÃ© des drifts par feature
                st.subheader("ğŸ“‹ Analyse par Feature")
                
                features_data = []
                for feature_name, feature_info in drift_report.get('features', {}).items():
                    if 'error' not in feature_info:
                        drift_status = "ğŸ”´ Drift" if feature_info.get('drift') else "ğŸŸ¢ OK"
                        p_value = feature_info.get('p_value', 'N/A')
                        
                        if feature_info.get('type') == 'numeric':
                            baseline_val = feature_info.get('baseline_mean', 'N/A')
                            current_val = feature_info.get('current_mean', 'N/A')
                        else:
                            baseline_val = "CatÃ©gorique"
                            current_val = "CatÃ©gorique"
                        
                        features_data.append({
                            'Feature': feature_name,
                            'Status': drift_status,
                            'P-Value': f"{p_value:.4f}" if isinstance(p_value, float) else p_value,
                            'Baseline': baseline_val,
                            'Current': current_val,
                            'Alert': feature_info.get('alert', '')
                        })
                
                if features_data:
                    df_drift = pd.DataFrame(features_data)
                    st.dataframe(df_drift, use_container_width=True)
                
                st.markdown("---")
                
                # Recommandations
                st.subheader("ğŸ“Œ Recommandations")
                
                if drift_report.get('overall_drift'):
                    st.error("""
                    âš ï¸ **DRIFT DÃ‰TECTÃ‰!**
                    
                    Actions recommandÃ©es:
                    1. ğŸ“Š Analyser les changements dans les donnÃ©es
                    2. ğŸ”„ VÃ©rifier la qualitÃ© des donnÃ©es
                    3. ğŸ”„ **RÃ©entraÃ®ner le modÃ¨le** avec les nouvelles donnÃ©es
                    4. âœ… CrÃ©er une nouvelle baseline aprÃ¨s rÃ©entraÃ®nement
                    """)
                else:
                    st.success("""
                    âœ… **Pas de drift dÃ©tectÃ©**
                    
                    Le modÃ¨le est stable et les donnÃ©es sont cohÃ©rentes avec la baseline.
                    Continuez Ã  monitorer rÃ©guliÃ¨rement.
                    """)
        else:
            st.info("ğŸ’¡ Faites une prÃ©diction d'abord pour tester le drift detection!")
    
    st.markdown("---")
    
    # Section 3: Guide
    st.subheader("ğŸ“š Comment Ã§a marche?")
    
    st.markdown("""
    **Data Drift** = Changement dans la distribution des donnÃ©es
    
    ### Types de Drift:
    - **Covariate Drift**: Changement des features (X)
    - **Concept Drift**: Changement de la relation entre X et Y
    - **Prior Probability Drift**: Changement de la distribution de Y
    
    ### DÃ©tection:
    - **NumÃ©riques**: Test Kolmogorov-Smirnov (KS)
    - **CatÃ©goriques**: Test Chi-carrÃ© (Ï‡Â²)
    
    ### Quand RÃ©entraÃ®ner:
    1. P-value < 0.05 â†’ Drift significatif
    2. Plus de 30% des features affectÃ©es
    3. Baisse de performance observÃ©e
    4. Changement de domaine (ex: nouvelle rÃ©gion, saison)
    """)
